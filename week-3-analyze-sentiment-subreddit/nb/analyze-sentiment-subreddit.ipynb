{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=‚Äùfalse‚Äù ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\" \n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "I changed this `secret.py` file into yaml credentials. \n",
    "The structure of the yaml is as follows:\n",
    "<code>\n",
    "REDDIT:\n",
    "    REDDIT_API_CLIENT_ID: \"your client id\"\n",
    "    REDDIT_API_CLIENT_SECRET: \"your secret\"\n",
    "    REDDIT_API_USER_AGENT: \"Your app name\"\n",
    "</code>\n",
    "\n",
    "My file was stored at `../credentials/secrets_reddit.yaml`, if you want to change it, you should edit the `CREDENTIALS_FILE` variable int `Task I` and `parse_args()` function in `Task IV`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\" id=\"heading\">Sentiment Analysis of Reddit Data using Reddit API</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this live coding session, we leverage the Python Reddit API Wrapper (`PRAW`) to retrieve data from subreddits on [Reddit](https://www.reddit.com), and perform sentiment analysis using [`pipelines`](https://huggingface.co/docs/transformers/main_classes/pipelines) from [HuggingFace ( ü§ó the GitHub of Machine Learning )](https://techcrunch.com/2022/05/09/hugging-face-reaches-2-billion-valuation-to-build-the-github-of-machine-learning/), powered by [transformer](https://arxiv.org/pdf/1706.03762.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the session, you will "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- know how to work with APIs\n",
    "- feel more comfortable navigating thru documentation, even inspecting the source code\n",
    "- understand what a `pipeline` object is in HuggingFace\n",
    "- perform sentiment analysis using `pipeline`\n",
    "- run a python script in command line and get the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How to Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- At the end of each task, commit* the work into the repository you created before the assignment\n",
    "- After completing all three tasks, make sure to push the notebook containing all code blocks and output cells to your repository you created before the assignment\n",
    "- Submit the link to the notebook in Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\\***NEVER** commit a notebook displaying errors unless it is instructed otherwise. However, commit often; recall git ABC = **A**lways **B**e **C**ommitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task I: Instantiate a Reddit API Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first task is to instantiate a Reddit API object using [PRAW](https://praw.readthedocs.io/en/stable/), through which you will retrieve data. PRAW is a wrapper for [Reddit API](https://www.reddit.com/dev/api) that makes interacting with the Reddit API easier unless you are already an expert of [`requests`](https://docs.python-requests.org/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1. Install packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Please ensure you've ran all the cells in the `imports.ipynb`, located [here](https://github.com/FourthBrain/MLE-8/blob/main/assignments/week-3-analyze-sentiment-subreddit/imports.ipynb), to make sure you have all the required packages for today's assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  2. Create a new app on Reddit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a new app on Reddit and save secret tokens; refer to [post in medium](https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Create a Reddit account if you don't have one, log into your account.\n",
    "- To access the API, we need create an app. Slight updates, on the website, you need to navigate to `preference` > `app`, or click [this link](https://www.reddit.com/prefs/apps) and scroll all the way down. \n",
    "- Click to create a new app, fill in the **name**, choose `script`, fill in  **description** and **redirect uri** ( The redirect URI is where the user is sent after they've granted OAuth access to your application (more info [here](https://github.com/reddit-archive/reddit/wiki/OAuth2)) For our purpose, you can enter some random url, e.g., www.google.com; as shown below.\n",
    "\n",
    "\n",
    "    <img src=\"https://miro.medium.com/max/700/1*lRBvxpIe8J2nZYJ6ucMgHA.png\" width=\"500\"/>\n",
    "- Jot down `client_id` (left upper corner) and `client_secret` \n",
    "\n",
    "    NOTE: CLIENT_ID refers to 'personal use script\" and CLIENT_SECRET to secret.\n",
    "    \n",
    "    <div>\n",
    "    <img src=\"https://miro.medium.com/max/700/1*7cGAKth1PMrEf2sHcQWPoA.png\" width=\"300\"/>\n",
    "    </div>\n",
    "\n",
    "- Create `secrets_reddit.py` in the same directory with this notebook, fill in `client_id` and `secret_id` obtained from the last step. We will need to import those constants in the next step.\n",
    "    ```\n",
    "    REDDIT_API_CLIENT_ID = \"client_id\"\n",
    "    REDDIT_API_CLIENT_SECRET = \"secret_id\"\n",
    "    REDDIT_API_USER_AGENT = \"any string except bot; ex. My User Agent\"\n",
    "    ```\n",
    "- Add `secrets_reddit.py` to your `.gitignore` file if not already done. NEVER push credentials to a repo, private or public. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3. Instantiate a `Reddit` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now you are ready to create a read-only `Reddit` instance. Refer to [documentation](https://praw.readthedocs.io/en/stable/code_overview/reddit_instance.html) when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import praw\n",
    "\n",
    "CREDENTIALS_FILE = '../credentials/secrets_reddit.yaml'\n",
    "\n",
    "with open(CREDENTIALS_FILE, \"r\") as f:\n",
    "    credentials = yaml.safe_load(f)\n",
    "    CLIENT_ID = credentials['REDDIT']['REDDIT_API_CLIENT_ID']\n",
    "    CLIENT_SECRET = credentials['REDDIT']['REDDIT_API_CLIENT_SECRET']\n",
    "    USER_AGENT = credentials['REDDIT']['REDDIT_API_USER_AGENT']\n",
    "\n",
    "# Create a Reddit object which allows us to interact with the Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=CLIENT_ID,\n",
    "    client_secret=CLIENT_SECRET,\n",
    "    #password=\"PASSWORD\",\n",
    "    user_agent=USER_AGENT,\n",
    "    #username=\"USERNAME\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<praw.reddit.Reddit object at 0x7f68e0e6d910>\n"
     ]
    }
   ],
   "source": [
    "print(reddit) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "```<praw.reddit.Reddit object at 0x10f8a0ac0>```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 4. Instantiate a `subreddit` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lastly, create a `subreddit` object for your favorite subreddit and inspect the object. The expected outputs you will see are from `r/machinelearning` unless otherwise specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "subreddit = reddit.subreddit('machinelearning')\n",
    "subreddit.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is the display name of the subreddit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "print (subreddit.display_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "    machinelearning\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How about its title, is it different from the display name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Machine Learning\n",
      "Display Name: MachineLearning\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "print (f'Title: {subreddit.title}')\n",
    "print (f'Display Name: {subreddit.display_name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "    Machine Learning\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Print out the description of the subreddit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**[Rules For Posts](https://www.reddit.com/r/MachineLearning/about/rules/)**\n",
      "--------\n",
      "+[Research](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AResearch)\n",
      "--------\n",
      "+[Discussion](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ADiscussion)\n",
      "--------\n",
      "+[Project](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AProject)\n",
      "--------\n",
      "+[News](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ANews)\n",
      "--------\n",
      "***[@slashML on Twitter](https://twitter.com/slashML)***\n",
      "--------\n",
      "***[Chat with us on Slack](https://join.slack.com/t/rml-talk/shared_invite/enQtNjkyMzI3NjA2NTY2LWY0ZmRjZjNhYjI5NzYwM2Y0YzZhZWNiODQ3ZGFjYmI2NTU3YjE1ZDU5MzM2ZTQ4ZGJmOTFmNWVkMzFiMzVhYjg)***\n",
      "--------\n",
      "**Beginners:**\n",
      "--------\n",
      "Please have a look at [our FAQ and Link-Collection](http://www.reddit.com/r/MachineLearning/wiki/index)\n",
      "\n",
      "[Metacademy](http://www.metacademy.org) is a great resource which compiles lesson plans on popular machine learning topics.\n",
      "\n",
      "For Beginner questions please try /r/LearnMachineLearning , /r/MLQuestions or http://stackoverflow.com/\n",
      "\n",
      "For career related questions, visit /r/cscareerquestions/\n",
      "\n",
      "--------\n",
      "\n",
      "[Advanced Courses (2016)](https://www.reddit.com/r/MachineLearning/comments/51qhc8/phdlevel_courses?st=isz2lqdk&sh=56c58cd6)\n",
      "\n",
      "[Advanced Courses (2020)](https://www.reddit.com/r/MachineLearning/comments/fdw0ax/d_advanced_courses_update/)\n",
      "\n",
      "--------\n",
      "**AMAs:**\n",
      "\n",
      "[Pluribus Poker AI Team 7/19/2019](https://www.reddit.com/r/MachineLearning/comments/ceece3/ama_we_are_noam_brown_and_tuomas_sandholm/)\n",
      "\n",
      "[DeepMind AlphaStar team (1/24//2019)](https://www.reddit.com/r/MachineLearning/comments/ajgzoc/we_are_oriol_vinyals_and_david_silver_from/)\n",
      "\n",
      "[Libratus Poker AI Team (12/18/2017)]\n",
      "(https://www.reddit.com/r/MachineLearning/comments/7jn12v/ama_we_are_noam_brown_and_professor_tuomas/)\n",
      "\n",
      "[DeepMind AlphaGo Team (10/19/2017)](https://www.reddit.com/r/MachineLearning/comments/76xjb5/ama_we_are_david_silver_and_julian_schrittwieser/)\n",
      "\n",
      "[Google Brain Team (9/17/2017)](https://www.reddit.com/r/MachineLearning/comments/6z51xb/we_are_the_google_brain_team_wed_love_to_answer/)\n",
      "\n",
      "[Google Brain Team (8/11/2016)]\n",
      "(https://www.reddit.com/r/MachineLearning/comments/4w6tsv/ama_we_are_the_google_brain_team_wed_love_to/)\n",
      "\n",
      "[The MalariaSpot Team (2/6/2016)](https://www.reddit.com/r/MachineLearning/comments/4m7ci1/ama_the_malariaspot_team/)\n",
      "\n",
      "[OpenAI Research Team (1/9/2016)](http://www.reddit.com/r/MachineLearning/comments/404r9m/ama_the_openai_research_team/)\n",
      "\n",
      "[Nando de Freitas (12/26/2015)](http://www.reddit.com/r/MachineLearning/comments/3y4zai/ama_nando_de_freitas/)\n",
      "\n",
      "[Andrew Ng and Adam Coates (4/15/2015)](http://www.reddit.com/r/MachineLearning/comments/32ihpe/ama_andrew_ng_and_adam_coates/)\n",
      "\n",
      "[J√ºrgen Schmidhuber (3/4/2015)](http://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama/)\n",
      "\n",
      "[Geoffrey Hinton (11/10/2014)]\n",
      "(http://www.reddit.com/r/MachineLearning/comments/2lmo0l/ama_geoffrey_hinton/)\n",
      "\n",
      "[Michael Jordan (9/10/2014)](http://www.reddit.com/r/MachineLearning/comments/2fxi6v/ama_michael_i_jordan/)\n",
      "\n",
      "[Yann LeCun (5/15/2014)](http://www.reddit.com/r/MachineLearning/comments/25lnbt/ama_yann_lecun/)\n",
      "\n",
      "[Yoshua Bengio (2/27/2014)](http://www.reddit.com/r/MachineLearning/comments/1ysry1/ama_yoshua_bengio/)\n",
      "\n",
      "--------\n",
      "Related Subreddit :\n",
      "\n",
      "* [LearnMachineLearning](http://www.reddit.com/r/LearnMachineLearning)\n",
      "\n",
      "* [Statistics](http://www.reddit.com/r/statistics)\n",
      "\n",
      "* [Computer Vision](http://www.reddit.com/r/computervision)\n",
      "\n",
      "* [Compressive Sensing](http://www.reddit.com/r/CompressiveSensing/)\n",
      "\n",
      "* [NLP] (http://www.reddit.com/r/LanguageTechnology)\n",
      "\n",
      "* [ML Questions] (http://www.reddit.com/r/MLQuestions)\n",
      "\n",
      "* /r/MLjobs and /r/BigDataJobs\n",
      "\n",
      "* /r/datacleaning\n",
      "\n",
      "* /r/DataScience\n",
      "\n",
      "* /r/scientificresearch\n",
      "\n",
      "* /r/artificial\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "print (subreddit.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>\n",
    "\n",
    "    **[Rules For Posts](https://www.reddit.com/r/MachineLearning/about/rules/)**\n",
    "    --------\n",
    "    +[Research](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AResearch)\n",
    "    --------\n",
    "    +[Discussion](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ADiscussion)\n",
    "    --------\n",
    "    +[Project](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AProject)\n",
    "    --------\n",
    "    +[News](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task II: Parse comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 1. Top Posts of All Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Find titles of top 10 posts of **all time** from your favorite subreddit. Refer to [Obtain Submission Instances from a Subreddit Section](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html)) if necessary. Verify if the titles match what you read on Reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0msubreddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtime_filter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mgenerator_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return a :class:`.ListingGenerator` for top items.\n",
       "\n",
       ":param time_filter: Can be one of: ``\"all\"``, ``\"day\"``, ``\"hour\"``,\n",
       "    ``\"month\"``, ``\"week\"``, or ``\"year\"`` (default: ``\"all\"``).\n",
       "\n",
       ":raises: :py:class:`ValueError` if ``time_filter`` is invalid.\n",
       "\n",
       "Additional keyword arguments are passed in the initialization of\n",
       ":class:`.ListingGenerator`.\n",
       "\n",
       "This method can be used like:\n",
       "\n",
       ".. code-block:: python\n",
       "\n",
       "    reddit.domain(\"imgur.com\").top(time_filter=\"week\")\n",
       "    reddit.multireddit(redditor=\"samuraisam\", name=\"programming\").top(time_filter=\"day\")\n",
       "    reddit.redditor(\"spez\").top(time_filter=\"month\")\n",
       "    reddit.redditor(\"spez\").comments.top(time_filter=\"year\")\n",
       "    reddit.redditor(\"spez\").submissions.top(time_filter=\"all\")\n",
       "    reddit.subreddit(\"all\").top(time_filter=\"hour\")\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/volumes/lib/python3.7/site-packages/praw/models/listing/mixins/base.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try run this line, what do you see? press q once you are done\n",
    "?subreddit.top "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Project] From books to presentations in 10s with AR + ML\n",
      "[D] A Demo from 1993 of 32-year-old Yann LeCun showing off the World's first Convolutional Network for Text Recognition\n",
      "[R] First Order Motion Model applied to animate paintings\n",
      "[N] AI can turn old photos into moving Images / Link is given in the comments - You can also turn your old photo like this\n",
      "[D] This AI reveals how much time politicians stare at their phone at work\n",
      "[D] Types of Machine Learning Papers\n",
      "[D] The machine learning community has a toxicity problem\n",
      "[Project] NEW PYTHON PACKAGE: Sync GAN Art to Music with \"Lucid Sonic Dreams\"! (Link in Comments)\n",
      "I made a robot that punishes me if it detects that if I am procrastinating on my assignments [P]\n",
      "[P] Using oil portraits and First Order Model to bring the paintings back to life\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "for idx, topic in enumerate(subreddit.top(limit=10)):\n",
    "    print (topic.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details> <summary>Expected output:</summary>\n",
    "\n",
    "    [Project] From books to presentations in 10s with AR + ML\n",
    "    [D] A Demo from 1993 of 32-year-old Yann LeCun showing off the World's first Convolutional Network for Text Recognition\n",
    "    [R] First Order Motion Model applied to animate paintings\n",
    "    [N] AI can turn old photos into moving Images / Link is given in the comments - You can also turn your old photo like this\n",
    "    [D] This AI reveals how much time politicians stare at their phone at work\n",
    "    [D] Types of Machine Learning Papers\n",
    "    [D] The machine learning community has a toxicity problem\n",
    "    [Project] NEW PYTHON PACKAGE: Sync GAN Art to Music with \"Lucid Sonic Dreams\"! (Link in Comments)\n",
    "    [P] Using oil portraits and First Order Model to bring the paintings back to life\n",
    "    [D] Convolution Neural Network Visualization - Made with Unity 3D and lots of Code / source - stefsietz (IG)    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2. Top 10 Posts of This Week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What are the titles of the top 10 posts of **this week** from your favorite subreddit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30% of Google's Reddit Emotions Dataset is Mislabeled [D]\n",
      "[R] mixed reality future ‚Äî see the world through artistic lenses ‚Äî made with NeRF\n",
      "[N] First-Ever Course on Transformers: NOW PUBLIC\n",
      "[D] Why are Corgi dogs so popular in machine learning (especially in the image generation community)?\n",
      "[D] Are there any rejected papers that ended up having significant impact in the long run?\n",
      "[D] Noam Chomsky on LLMs and discussion of LeCun paper (MLST)\n",
      "[N] Andrej Karpathy is leaving Tesla\n",
      "[R] So someone actually peer-reviewed this and thought \"yeah, looks good\"?\n",
      "[D] How do you verify the novelty of your research?\n",
      "[N] BigScience Releases their 176 Billion Parameter Open-access Multilingual Language Model\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "for idx, topic in enumerate(subreddit.top(limit=10, time_filter='week')):\n",
    "    print (topic.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details><summary>Expected output:</summary>\n",
    "\n",
    "    [N] Ian Goodfellow, Apple‚Äôs director of machine learning, is leaving the company due to its return to work policy. In a note to staff, he said ‚ÄúI believe strongly that more flexibility would have been the best policy for my team.‚Äù He was likely the company‚Äôs most cited ML expert.\n",
    "    [R][P] Thin-Plate Spline Motion Model for Image Animation + Gradio Web Demo\n",
    "    [P] I‚Äôve been trying to understand the limits of some of the available machine learning models out there. Built an app that lets you try a mix of CLIP from Open AI + Apple‚Äôs version of MobileNet, and more directly on your phone's camera roll.\n",
    "    [R] Meta is releasing a 175B parameter language model\n",
    "    [N] Hugging Face raised $100M at $2B to double down on community, open-source & ethics\n",
    "    [P] T-SNE to view and order your Spotify tracks\n",
    "    [D] : HELP Finding a Book - A book written for Google Engineers about foundational Math to support ML\n",
    "    [R] Scaled up CLIP-like model (~2B) shows 86% Zero-shot on Imagenet\n",
    "    [D] Do you use NLTK or Spacy for text preprocessing?\n",
    "    [D] Democratizing Diffusion Models - LDMs: High-Resolution Image Synthesis with Latent Diffusion Models, a 5-minute paper summary by Casual GAN Papers\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "Check out what other attributes the `praw.models.Submission` class has in the [docs](https://praw.readthedocs.io/en/stable/code_overview/models/submission.html). \n",
    "\n",
    "1. After having a chance to look through the docs, is there any other information that you might want to extract? How might this additional data help you?\n",
    "\n",
    "Write a sample piece of code below extracting three additional pieces of information from the submission below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Upvote ratio</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30% of Google's Reddit Emotions Dataset is Mis...</td>\n",
       "      <td>BB4evaTB12</td>\n",
       "      <td>0.98</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[R] mixed reality future ‚Äî see the world throu...</td>\n",
       "      <td>SpatialComputing</td>\n",
       "      <td>0.96</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[N] First-Ever Course on Transformers: NOW PUBLIC</td>\n",
       "      <td>DragonLord9</td>\n",
       "      <td>0.92</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[D] Why are Corgi dogs so popular in machine l...</td>\n",
       "      <td>Azuresonance</td>\n",
       "      <td>0.92</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[D] Are there any rejected papers that ended u...</td>\n",
       "      <td>TheSurvivingHalf</td>\n",
       "      <td>0.98</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[D] Noam Chomsky on LLMs and discussion of LeC...</td>\n",
       "      <td>timscarfe</td>\n",
       "      <td>0.88</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[N] Andrej Karpathy is leaving Tesla</td>\n",
       "      <td>EffectSizeQueen</td>\n",
       "      <td>0.94</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[R] So someone actually peer-reviewed this and...</td>\n",
       "      <td>fanconic</td>\n",
       "      <td>0.96</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[D] How do you verify the novelty of your rese...</td>\n",
       "      <td>ajt9000</td>\n",
       "      <td>0.99</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[N] BigScience Releases their 176 Billion Para...</td>\n",
       "      <td>MonLiH</td>\n",
       "      <td>0.98</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title            Author  \\\n",
       "0  30% of Google's Reddit Emotions Dataset is Mis...        BB4evaTB12   \n",
       "1  [R] mixed reality future ‚Äî see the world throu...  SpatialComputing   \n",
       "2  [N] First-Ever Course on Transformers: NOW PUBLIC       DragonLord9   \n",
       "3  [D] Why are Corgi dogs so popular in machine l...      Azuresonance   \n",
       "4  [D] Are there any rejected papers that ended u...  TheSurvivingHalf   \n",
       "5  [D] Noam Chomsky on LLMs and discussion of LeC...         timscarfe   \n",
       "6               [N] Andrej Karpathy is leaving Tesla   EffectSizeQueen   \n",
       "7  [R] So someone actually peer-reviewed this and...          fanconic   \n",
       "8  [D] How do you verify the novelty of your rese...           ajt9000   \n",
       "9  [N] BigScience Releases their 176 Billion Para...            MonLiH   \n",
       "\n",
       "  Upvote ratio Score  \n",
       "0         0.98   865  \n",
       "1         0.96   355  \n",
       "2         0.92   351  \n",
       "3         0.92   314  \n",
       "4         0.98   288  \n",
       "5         0.88   277  \n",
       "6         0.94   274  \n",
       "7         0.96   240  \n",
       "8         0.99   181  \n",
       "9         0.98   183  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(columns = ('Title', 'Author', 'Upvote ratio', 'Score'))\n",
    "for idx, topic in enumerate(subreddit.top(limit=10, time_filter='week')):\n",
    "    df.loc[idx, :] = (topic.title, topic.author, topic.upvote_ratio, topic.score)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "2. Is there any information available that might be a concern when it comes to Ethical Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "I am not sure about the meaning of this question. If by `ethical data` you mean the data that should not be displayed to everyone, then not really, at least not in Machine learning. However, there is this `over_18` feature that may serve such a purpose in other cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 3. Comment Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Add comments to the code block below to describe what each line of the code does (Refer to [Obtain Comment Instances Section](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html) when necessary). The code is adapted from [this tutorial](https://praw.readthedocs.io/en/stable/tutorials/comments.html)\n",
    "\n",
    "The purpose is \n",
    "1. to understand what the code is doing \n",
    "2. start to comment your code whenever it is not self-explantory if you have not (others will thank you, YOU will thank you later üòä) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 239 ms, sys: 14.8 ms, total: 254 ms\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from praw.models import MoreComments\n",
    "\n",
    "# YOUR COMMENT HERE\n",
    "top_comments = []\n",
    "# YOUR COMMENT HERE\n",
    "# Iterate over top 10 topics ever\n",
    "for submission in subreddit.top(limit=10):\n",
    "    # YOUR COMMENT HERE\n",
    "    # For each topic iterate over all comments\n",
    "    # Each comment may be an inscance of either `comment` or `MoreComments` class. \n",
    "    for top_level_comment in submission.comments:\n",
    "        # YOUR COMMENT HERE\n",
    "        # If the comment is an instance of `MoreComments` class, it contains subcomments\n",
    "        # Here in the code we ignore it.\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "        # YOUR COMMENT HERE\n",
    "        # Otherwise, the comment is just a comment. We are added the body of such comment\n",
    "        # to the list.\n",
    "        top_comments.append(top_level_comment.body)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 4. Inspect Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How many comments did you extract from the last step? Examine a few comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We extracted 739 comments. This number does not contain nested comments (instances of MoreComments class)\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE  # the answer may vary 693 for r/machinelearning\n",
    "print (f'We extracted {len(top_comments)} comments. This number does not contain nested comments (instances of MoreComments class)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u/fabiomb el otro d√≠a dec√≠as que andaba porque ten√≠a fondo de color blanco plano.',\n",
       " 'Alan Turing woke up from his grave?',\n",
       " 'Since when did the sub start accepting memes??']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "[random.choice(top_comments) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details> <summary>Some of the comments from `r/machinelearning` subreddit are:</summary>\n",
    "\n",
    "    ['Awesome visualisation',\n",
    "    'Similar to a stack or connected neurons.',\n",
    "    'Will this Turing pass the Turing Test?']\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "3. After having a chance to review a few samples of 5 comments from the subreddit, what can you say about the data? \n",
    "\n",
    "HINT: Think about the \"cleanliness\" of the data, the content of the data, think about what you're trying to do - how does this data line up with your goal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "I believe that the way of presenting this data (just bodies of comments) is not appropriate for analysis. I do not have any specific goal regarding this data, but addressing any business or research questions most likely requires analysis of both topics and comments, not comments only. My answer is that I would start with using a tree structure to store the data and check more than just the comments bodies. Just displaying comments is not enough; I can get better insight using Reddit directly, without API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 5. Extract Top Level Comment from Subreddit `TSLA`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Write your code to extract top level comments from the top 10 topics of a time period, e.g., year, from subreddit `TSLA` and store them in a list `top_comments_tsla`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# I assume that I am supposed to exclude these MoreComments objects again.\n",
    "subreddit_tsla = reddit.subreddit('TSLA')\n",
    "\n",
    "top_comments_tsla = []\n",
    "for submission in subreddit_tsla.top(limit=10):\n",
    "    top_comments_tsla += [x.body for x in submission.comments if not isinstance(x, MoreComments)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_comments_tsla) # Expected: 174 for r/machinelearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FACTS SIR!!!üòíüòåüòîüò™',\n",
       " 'Maybe we‚Äôre all a little crazy‚Ä¶but I‚Äôm holding and hoping that it‚Äôs a great call today. It will be brutal if there are surprises in Q1 or forecast. Hopefully Shanghai won‚Äôt be a reason for continued selling. Investors are in a bear mood over NFLX!',\n",
       " \"I'm sure they will do it but only because we all know what it will do to the stock.  ;)\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[random.choice(top_comments_tsla) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Some of the comments from `r/TSLA` subreddit:</summary>\n",
    "\n",
    "    ['I bought puts',\n",
    "    '100%',\n",
    "    'Yes. And I‚Äôm bag holding 1200 calls for Friday and am close to throwing myself out the window']\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "4. Now that you've had a chance to review another subreddits comments, do you see any differences in the kinds of comments either subreddit has - and how might this relate to bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "From a data scientist perspective: judging the potential bias based on a few comments would introduce additional bias based on my own views and prejudices. We may safely assume that people writing in different subreddits may have different characteristics, but I would not dare to describe such characteristics based on the presented data.\n",
    "\n",
    "Maybe I am missing the gist of this question, I could not participate in a live coding session. Sorry for this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# CONTINUE HERE\n",
    "\n",
    "### Task III: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us analyze the sentiment of comments scraped from `r/TSLA` using a pre-trained HuggingFace model to make the inference. Take a [Quick tour](https://huggingface.co/docs/transformers/quicktour). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1. Import `pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2. Create a Pipeline to Perform Task \"sentiment-analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5528f59048b744958a3a2a399a279207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1160.0, style=ProgressStyle(description‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
     ]
    }
   ],
   "source": [
    "sentiment_model = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3. Get one comment from list `top_comments_tsla` from Task II - 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "comment = random.choice(top_comments_tsla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Just maybe it's happening now, adjusting value to expected earnings in an ever more competitive market\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example comment is: `'Bury Burry!!!!!'`. Print out what you get. For reproducibility, use the same comment in the next step; consider setting a seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 4. Make Inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentiment = sentiment_model(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is the type of the output `sentiment`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: [{'label': 'NEU', 'score': 0.8963178396224976}]\n",
      "Sentiment type: <class 'list'>, Sentiment elem type: <class 'dict'>\n",
      "{'label': 'NEU', 'score': 0.8963178396224976}\n"
     ]
    }
   ],
   "source": [
    "print ('Sentiment:', sentiment)\n",
    "print (f'Sentiment type: {type(sentiment)}, Sentiment elem type: {type(sentiment[0])}')\n",
    "print(sentiment[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "It is a list of dictionaries. Each dictionary corresponds to one element from the input data and contains the label (POS/NEG/NEU for this particular model) and the score  that can be understood as a confidence level of the prediction (technically, it is probably the top softmax output, but I did not check the model code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The comment: Just maybe it's happening now, adjusting value to expected earnings in an ever more competitive market\n",
      "Predicted Label is NEU and the score is 0.896\n"
     ]
    }
   ],
   "source": [
    "print(f'The comment: {comment}')\n",
    "print(f'Predicted Label is {sentiment[0][\"label\"]} and the score is {sentiment[0][\"score\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the example comment, the output is:\n",
    "\n",
    "    The comment: Bury Burry!!!!!\n",
    "    Predicted Label is NEGATIVE and the score is 0.989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üñ•Ô∏è‚ùì Model Question:\n",
    "\n",
    "1. What does the score represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task IV: Put All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull all the piece together, create a simple script that does \n",
    "\n",
    "- get the subreddit\n",
    "- get comments from the top posts for given subreddit\n",
    "- run sentiment analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete the Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you complete the code, running the following block writes the code into a new Python script and saves it as `top_tlsa_comment_sentiment.py` under the same directory with the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting top_tlsa_comment_sentiment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile top_tlsa_comment_sentiment.py\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Tensorflow errors only\n",
    "\n",
    "#import secrets\n",
    "import yaml\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "from typing import Dict, List\n",
    "\n",
    "from praw import Reddit\n",
    "from praw.models.reddit.subreddit import Subreddit\n",
    "from praw.models import MoreComments\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser=argparse.ArgumentParser(description=\"Setiment analysis script\")\n",
    "    parser.add_argument(\"-c\", \"--credentials\", default='../credentials/secrets_reddit.yaml',\n",
    "                        help=\"yaml with credentials\")\n",
    "    args=parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def get_subreddit(display_name:str, credentials_file:str) -> Subreddit:\n",
    "    \"\"\"Get subreddit object from display name\n",
    "\n",
    "    Args:\n",
    "        display_name (str): [description]\n",
    "\n",
    "    Returns:\n",
    "        Subreddit: [description]\n",
    "    \"\"\"\n",
    "    with open(credentials_file, \"r\") as f:\n",
    "        credentials = yaml.safe_load(f)    \n",
    "        reddit = Reddit(\n",
    "            client_id=credentials['REDDIT']['REDDIT_API_CLIENT_ID'],        \n",
    "            client_secret=credentials['REDDIT']['REDDIT_API_CLIENT_SECRET'],\n",
    "            user_agent=credentials['REDDIT']['REDDIT_API_USER_AGENT']\n",
    "        )\n",
    "    \n",
    "    subreddit = reddit.subreddit(display_name=display_name)\n",
    "    return subreddit\n",
    "\n",
    "\n",
    "def get_comments(subreddit:Subreddit, limit:int=3) -> List[str]:\n",
    "    \"\"\" Get comments from subreddit\n",
    "\n",
    "    Args:\n",
    "        subreddit (Subreddit): [description]\n",
    "        limit (int, optional): [description]. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of comments\n",
    "    \"\"\"\n",
    "    top_comments = []\n",
    "    for submission in subreddit.top(limit=limit):\n",
    "        #for top_level_comment in submission.comments:\n",
    "        #    if isinstance(top_level_comment, MoreComments):\n",
    "        #        continue\n",
    "        #    top_comments.append(top_level_comment.body)\n",
    "        top_comments += [x.body for x in submission.comments if not isinstance(x, MoreComments)]\n",
    "    return top_comments\n",
    "\n",
    "def run_sentiment_analysis(comment:str) -> Dict:\n",
    "    \"\"\"Run sentiment analysis on comment using default distilbert model\n",
    "    \n",
    "    Args:\n",
    "        comment (str): [description]\n",
    "        \n",
    "    Returns:\n",
    "        str: Sentiment analysis result\n",
    "    \"\"\"\n",
    "    sentiment_model = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "    sentiment = sentiment_model(comment)\n",
    "    return sentiment[0]\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    subreddit = get_subreddit('tsla', credentials_file=args.credentials)\n",
    "    comments = get_comments(subreddit)\n",
    "    comment = random.choice(comments)\n",
    "    sentiment = run_sentiment_analysis(comment)\n",
    "    \n",
    "    print(f'The comment: {comment}')\n",
    "    print(f'Predicted Label is {sentiment[\"label\"]} and the score is {sentiment[\"score\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following block to see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.13k/1.13k [00:00<00:00, 1.54MB/s]\n",
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "The comment: Give this man a raise! (In BTC)\n",
      "Predicted Label is POS and the score is 0.978\n"
     ]
    }
   ],
   "source": [
    "!python top_tlsa_comment_sentiment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> Expected output:</summary>\n",
    "\n",
    "    No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
    "    The comment: When is DOGE flying\n",
    "    Predicted Label is POSITIVE and the score is 0.689\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "5. Is the subreddit active? About how many posts or threads per day? How could you find this information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESLA:            On average, there is a new submission every 18.2 hour. It gives 1.32 submissions per day.\n",
      "MACHINE_LEARNING: On average, there is a new submission every 1.9 hour. It gives 12.83 submissions per day.\n"
     ]
    }
   ],
   "source": [
    "def print_frequency(subreddit, message_id='', nr_submissions = 300):\n",
    "    uct_list = []\n",
    "    for submission in subreddit.new(limit=nr_submissions):\n",
    "        uct_list.append(submission.created_utc)\n",
    "\n",
    "    comment_dur = (max(uct_list) - min(uct_list)) / len(uct_list)\n",
    "\n",
    "    print (f'{message_id}On average, there is a new submission every {comment_dur / 3600:.1f} hour. It gives {24*3600/comment_dur:.2f} submissions per day.')\n",
    "\n",
    "print_frequency(subreddit_tsla, 'TESLA:            ')\n",
    "print_frequency(subreddit,      'MACHINE_LEARNING: ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "Machine learning is much more active subreddit. However, for a relatively niche area, Tesla is also doing well. A new post every 18 hours seems quite active to me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "6. Does there seem to be a large distribution of posters or a smaller concentration of posters who are very active? What kind of impact might this have on the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_authors(subreddit, nr_submissions = 300):\n",
    "    df = pd.DataFrame(columns = ['nr_submissions'])\n",
    "    for submission in subreddit.new(limit=300):\n",
    "        author = submission.author\n",
    "        if author in df.index:\n",
    "            df.at[author, 'nr_submissions'] = df.at[author, 'nr_submissions'] + 1\n",
    "        else:\n",
    "            df.at[author, 'nr_submissions'] = 1\n",
    "    return df\n",
    "\n",
    "df_tsla = get_authors(subreddit_tsla)\n",
    "df_ml = get_authors(subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure()\n",
    "df_tsla.plot.hist()\n",
    "plt.title('Tesla')\n",
    "df_ml.plot.hist()\n",
    "plt.title('Machine Learning');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "Based on the last 300 submissions, the distribution of posters is large. It is larger in the ML group than in the Tesla group. It was expected. ML is a more general group, so more posters are involved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "c57794392b841cffd8686d5c4548e4e2ec78521f49300d60954d1380f1b4bd1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
